{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734e31bf",
   "metadata": {},
   "source": [
    "## Урок 6. Сегментация\n",
    "### Практическое задание\n",
    "Попробуйте обучить нейронную сеть U-Net на любом другом датасете.\n",
    "\n",
    "Опишите результат. Что помогло повысить точность?\n",
    "\n",
    "*Попробуйте свои силы в задаче City Scapes на Kaggle - https://www.kaggle.com/dansbecker/cityscapes-image-pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc034aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/examples.git\n",
    "!pip install tensorflow_datasets\n",
    "!pip install tensorflow_datasets==3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5376e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets\n",
    "mnist = tensorflow_datasets.load('mnist')\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_train = 'archive/cityscapes_data/train'\n",
    "path_images_val = 'archive/cityscapes_data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = os.listdir(path_images_train)\n",
    "img_val = os.listdir(path_images_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b77205",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_example = cv2.imread(path_images_train + img_train[0])\n",
    "plt.imshow(img_example)\n",
    "print(img_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e785fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_y = img_example.shape[0]\n",
    "size_x = img_example.shape[1]\n",
    "norm_size_x_for_image = int(size_x / 2)\n",
    "len_train = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b73b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train = np.zeros((len_train, size_y, norm_size_x_for_image, 3))\n",
    "y_train = np.zeros((len_train, size_y, norm_size_x_for_image, 3))\n",
    "index = 0\n",
    "\n",
    "for name_img in img_train[:len_train]:\n",
    "    img = cv2.imread(path_images_train+name_img)[:,:256]/256\n",
    "    mask = cv2.imread(path_images_train+name_img)[:,256:]/256\n",
    "    x_train[index] = tf.image.resize(img, (256, 256))\n",
    "    y_train[index] = tf.image.resize(mask, (256, 256))\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14626d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "EPOCHS = 50 \n",
    "BATCH = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4db65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(256,256,3),\n",
    "                                               include_top=False)\n",
    "\n",
    "# Use the activations of these layers\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 128x128\n",
    "    'block_3_expand_relu',   # 64x64\n",
    "    'block_6_expand_relu',   # 32x32\n",
    "    'block_13_expand_relu',  # 16x16\n",
    "    'block_16_project',      # 8x8\n",
    "]\n",
    "layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_stack = [\n",
    "    pix2pix.upsample(512, 3),  # 8x8 -> 16x16\n",
    "    pix2pix.upsample(256, 3),  # 16x16 -> 32x32\n",
    "    pix2pix.upsample(128, 3),  # 32x32 -> 64x64\n",
    "    pix2pix.upsample(64, 3),   # 64x64 -> 128x128\n",
    "]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(output_channels):\n",
    "  inputs = tf.keras.layers.Input(shape=(256,256,3))\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = down_stack(x)\n",
    "  x = skips[-1]\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    x = concat([x, skip])\n",
    "\n",
    "  # This is the last layer of the model\n",
    "  last = tf.keras.layers.Conv2DTranspose(\n",
    "      output_channels, 3, strides=2,\n",
    "      padding='same')  #128x128 -> 256x256\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(OUTPUT_CHANNELS)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad600d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_train[1500:]\n",
    "y_test = y_train[1500:]\n",
    "x_train = x_train[:1500]\n",
    "y_train = y_train[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca780fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(x_train, y_train, \n",
    "                          epochs=EPOCHS,\n",
    "                          batch_size=BATCH,\n",
    "                          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdbaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.grid('on')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cabc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_history.history['accuracy']\n",
    "val_accuracy = model_history.history['val_accuracy']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, accuracy, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.grid('on')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883fcf38",
   "metadata": {},
   "source": [
    "Данные и обучение модели занимают достаточно много ОЗУ, поэтому для обучения было использовано 1500 объектов из 2975. Для валидации было использовано 500 объектов.\n",
    "Для стабильного результата достаточно около 35 эпох обучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
